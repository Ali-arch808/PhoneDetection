{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af466933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    " \n",
    "!pip install -U git+https://github.com/qubvel/efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb87bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "#from tf import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Dropout,Conv2D,MaxPooling2D, Flatten,BatchNormalization, Activation\n",
    "from keras.optimizers import RMSprop , Adam ,SGD\n",
    "from keras.preprocessing import image \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from IPython.display import Image \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import efficientnet.keras as enet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62af56d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import sigmoid\n",
    "\n",
    "\n",
    "class SwishActivation(Activation):\n",
    "\n",
    "    def __init__(self, activation, **kwargs):\n",
    "        super(SwishActivation, self).__init__(activation, **kwargs)\n",
    "        self.__name__ = 'swish_act'\n",
    "\n",
    "\n",
    "def swish_act(x, beta=1):\n",
    "    return (x * sigmoid(beta * x))\n",
    "\n",
    "\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.layers import Activation\n",
    "\n",
    "get_custom_objects().update({'swish_act': SwishActivation(swish_act)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37051c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = enet.EfficientNetB0(include_top=False, input_shape=(150,50,3), pooling='avg', weights='imagenet')\n",
    " \n",
    "# Adding 2 fully-connected layers to B0.\n",
    "x = model.output\n",
    " \n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.7)(x)\n",
    " \n",
    "x = Dense(512)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Activation(swish_act)(x)\n",
    "x = Dropout(0.5)(x)\n",
    " \n",
    "x = Dense(128)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(swish_act)(x)\n",
    " \n",
    "x = Dense(64)(x)\n",
    " \n",
    "x = Dense(32)(x)\n",
    " \n",
    "x = Dense(16)(x)\n",
    " \n",
    "# Output layer\n",
    "predictions = Dense(1, activation=\"sigmoid\")(x)\n",
    " \n",
    "model_final = Model(inputs = model.input, outputs = predictions)\n",
    " \n",
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ed2e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(0.0001),\n",
    "              metrics=['accuracy'])\n",
    " \n",
    "mcp_save = ModelCheckpoint('/gdrive/My Drive/EnetB0_CIFAR10_TL.h5', save_best_only=True, monitor='val_acc')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2, verbose=1,)\n",
    "#print(\"Training....\")\n",
    "model_final.fit(x_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=10,\n",
    "              validation_split=0.1,\n",
    "              callbacks=[mcp_save, reduce_lr],\n",
    "              shuffle=True,\n",
    "              verbose=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b3fcd2da",
   "metadata": {},
   "source": [
    "Train on 7348 samples, validate on 817 samples\n",
    "Epoch 1/10\n",
    "7348/7348 [==============================] - 452s 61ms/step - loss: 0.2135 - accuracy: 0.9075 - val_loss: 0.1309 - val_accuracy: 0.9621\n",
    "Epoch 2/10\n",
    "7348/7348 [==============================] - 418s 57ms/step - loss: 0.0174 - accuracy: 0.9966 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
    "Epoch 3/10\n",
    "7348/7348 [==============================] - 422s 57ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 9.2454e-04 - val_accuracy: 1.0000\n",
    "Epoch 4/10\n",
    "7348/7348 [==============================] - 418s 57ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 1.3291e-04 - val_accuracy: 1.0000\n",
    "Epoch 5/10\n",
    "7348/7348 [==============================] - 422s 57ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 1.2502e-04 - val_accuracy: 1.0000\n",
    "Epoch 6/10\n",
    "7348/7348 [==============================] - 422s 57ms/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 1.1914e-04 - val_accuracy: 1.0000\n",
    "Epoch 7/10\n",
    "7348/7348 [==============================] - 418s 57ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 6.5256e-05 - val_accuracy: 1.0000\n",
    "Epoch 8/10\n",
    "7348/7348 [==============================] - 414s 56ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 4.6783e-05 - val_accuracy: 1.0000\n",
    "Epoch 9/10\n",
    "7348/7348 [==============================] - 420s 57ms/step - loss: 9.6152e-04 - accuracy: 0.9999 - val_loss: 2.0692e-05 - val_accuracy: 1.0000\n",
    "Epoch 10/10\n",
    "7348/7348 [==============================] - 422s 57ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 2.2230e-05 - val_accuracy: 1.0000\n",
    "<keras.callbacks.callbacks.History at 0x7f8ea9f04390>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1612b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Accuracy: {}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6e1d6b15",
   "metadata": {},
   "source": [
    "Test Accuracy: 100.0%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ee4cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH=50\n",
    "HIGHT=150\n",
    "CHANNEL=3\n",
    " \n",
    "def create_validation_data(DataDir):\n",
    "    validation_data = []\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DataDir, category) # path to each class dir\n",
    "        test_class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try :\n",
    "                img_array = image.load_img(os.path.join(path,img),target_size=(HIGHT,WIDTH,CHANNEL))\n",
    "                validation_data.append([img_array,test_class_num])\n",
    "            except :\n",
    "                pass\n",
    "    return validation_data\n",
    " \n",
    "valdiation_data=create_validation_data(DATADIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3906ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_batch_size=7\n",
    "test_dir=DATADIR\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(150, 50),\n",
    "        color_mode=\"rgb\",\n",
    "        shuffle = False,\n",
    "        class_mode='binary',\n",
    "        batch_size=desired_batch_size)\n",
    " \n",
    "filenames = test_generator.filenames\n",
    "nb_samples = len(filenames)\n",
    " \n",
    "predict = model_final.predict_generator(test_generator,steps = \n",
    "                                   np.ceil(nb_samples/desired_batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296b3ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 10 epoch\n",
    "def validation(test_dir):\n",
    "    desired_batch_size = 7\n",
    "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(150, 50),\n",
    "        color_mode=\"rgb\",\n",
    "        shuffle=False,\n",
    "        class_mode='binary',\n",
    "        batch_size=desired_batch_size)\n",
    "\n",
    "    filenames = test_generator.filenames\n",
    "    nb_samples = len(filenames)\n",
    "\n",
    "    predict = model_final.predict_generator(test_generator, steps=\n",
    "    np.ceil(nb_samples / desired_batch_size))\n",
    "\n",
    "    correct = 0\n",
    "\n",
    "    category = [\"n\", \"p\"]\n",
    "    True_posetives = 0\n",
    "    True_negatives = 0\n",
    "    False_posetives = 0\n",
    "    False_negatives = 0\n",
    "\n",
    "    valdiation_data = create_validation_data(test_dir)\n",
    "\n",
    "    for i in range(len(predict)):\n",
    "\n",
    "        prediction = category[int(round(predict[i][0]))]\n",
    "        label = valdiation_data[i][1]\n",
    "        img_array = valdiation_data[i][0]\n",
    "\n",
    "        if prediction != category[label]:\n",
    "            plt.title('prediction:{0}   label:{1}'.format(prediction, category[label]))\n",
    "            plt.imshow(img_array, cmap=plt.get_cmap('gray'))\n",
    "            plt.show()\n",
    "        if prediction == \"p\" and category[label] == \"p\":\n",
    "            correct += 1\n",
    "            True_posetives += 1\n",
    "        elif prediction == \"n\" and category[label] == \"n\":\n",
    "            True_negatives += 1\n",
    "            correct += 1\n",
    "        elif prediction == \"p\" and category[label] == \"n\":\n",
    "            False_posetives += 1\n",
    "        elif prediction == \"n\" and category[label] == \"p\":\n",
    "            False_negatives += 1\n",
    "\n",
    "    total_number_of_samples = len(predict)\n",
    "\n",
    "    ##acc = (True_posetives+False_negatives)/total_number_of_samples\n",
    "\n",
    "    acc = correct / total_number_of_samples\n",
    "\n",
    "    print(\"Total number of samples \", total_number_of_samples)\n",
    "    print(\"True_posetives \", True_posetives)\n",
    "    print(\"True_negatives \", True_negatives)\n",
    "    print(\"False_posetive \", False_posetives)\n",
    "    print(\"False_negative \", False_negatives)\n",
    "\n",
    "    print(\"accuracy \", acc)\n",
    "\n",
    "\n",
    "validation('test_4')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0f815adc",
   "metadata": {},
   "source": [
    "Found 128 images belonging to 2 classes.\n",
    "Total number of samples  128\n",
    "True_posetives  67\n",
    "True_negatives  54\n",
    "False_posetive  5\n",
    "False_negative  2\n",
    "accuracy  0.9453125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97ae410",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation('test_3')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f756628",
   "metadata": {},
   "source": [
    " Found 161 images belonging to 2 classes.\n",
    "\n",
    "Total number of samples  161\n",
    "True_posetives  79\n",
    "True_negatives  81\n",
    "False_posetive  0\n",
    "False_negative  1\n",
    "accuracy  0.9937888198757764"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0306b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation('these as test')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2244b875",
   "metadata": {},
   "source": [
    " Total number of samples  882\n",
    "True_posetives  395\n",
    "True_negatives  357\n",
    "False_posetive  54\n",
    "False_negative  76\n",
    "accuracy  0.8526077097505669"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
